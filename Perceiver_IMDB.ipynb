{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42a4dfdcaacb4ba1aceb2c879eba1f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c38cc9f86a6f4ba6b204bf4896fcae0c",
              "IPY_MODEL_b60fbfc7e9944de4a69a3cf6a019a2d8",
              "IPY_MODEL_986574032eb845a695007934ca6ac365"
            ],
            "layout": "IPY_MODEL_231c11f423054636a3e39ca3ae95b2d5"
          }
        },
        "c38cc9f86a6f4ba6b204bf4896fcae0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a83957630514f37acb89d09eaae165e",
            "placeholder": "​",
            "style": "IPY_MODEL_88910ecfa21e4990b2e96fd7bdac6694",
            "value": "100%"
          }
        },
        "b60fbfc7e9944de4a69a3cf6a019a2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb9afe368bd247ecab75b75d57b4176c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9749a6d62d804961bf0f16932697dad3",
            "value": 2
          }
        },
        "986574032eb845a695007934ca6ac365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7aa732b5d12408b958fec72195910cf",
            "placeholder": "​",
            "style": "IPY_MODEL_18f8f463c2b44e24b1abfb87bfae7963",
            "value": " 2/2 [00:00&lt;00:00, 65.49it/s]"
          }
        },
        "231c11f423054636a3e39ca3ae95b2d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a83957630514f37acb89d09eaae165e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88910ecfa21e4990b2e96fd7bdac6694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb9afe368bd247ecab75b75d57b4176c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9749a6d62d804961bf0f16932697dad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7aa732b5d12408b958fec72195910cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f8f463c2b44e24b1abfb87bfae7963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd2549fe803f4fe98f009a882b8110fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52d0de07ee414a8087bd85ae0239776d",
              "IPY_MODEL_b95832bbbb374016baf0f3f7459314f7",
              "IPY_MODEL_f079e026c2bc40659ec8a5cbb45f801c"
            ],
            "layout": "IPY_MODEL_a078920956c149249ba9579d54d376d7"
          }
        },
        "52d0de07ee414a8087bd85ae0239776d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f36037a6c2ac464195f753310a80278a",
            "placeholder": "​",
            "style": "IPY_MODEL_a069f41bc54c4861ac3b25b88b828a6b",
            "value": "Downloading builder script: "
          }
        },
        "b95832bbbb374016baf0f3f7459314f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c9b3cb072414e7e9d62805ec9a2d90d",
            "max": 1652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02f398e8aa884dcfb8ea0f88e516f7ce",
            "value": 1652
          }
        },
        "f079e026c2bc40659ec8a5cbb45f801c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6d2655749074a7ea959a8542e56e147",
            "placeholder": "​",
            "style": "IPY_MODEL_4a722eadc7954ca6adf678dbb217a31a",
            "value": " 4.21k/? [00:00&lt;00:00, 140kB/s]"
          }
        },
        "a078920956c149249ba9579d54d376d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f36037a6c2ac464195f753310a80278a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a069f41bc54c4861ac3b25b88b828a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c9b3cb072414e7e9d62805ec9a2d90d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02f398e8aa884dcfb8ea0f88e516f7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6d2655749074a7ea959a8542e56e147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a722eadc7954ca6adf678dbb217a31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a9a2c37235f445fb50417e08b539973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b257c583501471186c0e8d43ce22fd5",
              "IPY_MODEL_a23322e5b92e47dabca5b6136ed2d59e",
              "IPY_MODEL_4c8a6478d4d2416eac1c25339231daa5"
            ],
            "layout": "IPY_MODEL_d514345ccf0242f1b2a48d415f922b1c"
          }
        },
        "2b257c583501471186c0e8d43ce22fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df2e565a49c4441d821a7006e23efc39",
            "placeholder": "​",
            "style": "IPY_MODEL_8bcdf54658564c1190311ef0dcc61327",
            "value": "100%"
          }
        },
        "a23322e5b92e47dabca5b6136ed2d59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94406e4e86a94017aee5d3c669c16f40",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b912ff98d6d54e0db0236788fbe3295c",
            "value": 500
          }
        },
        "4c8a6478d4d2416eac1c25339231daa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007d3b997b6942fea809f771a995d6cc",
            "placeholder": "​",
            "style": "IPY_MODEL_9ffe29eb55ad4d3eb92a52e417dbd325",
            "value": " 500/500 [01:04&lt;00:00,  7.76it/s]"
          }
        },
        "d514345ccf0242f1b2a48d415f922b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df2e565a49c4441d821a7006e23efc39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bcdf54658564c1190311ef0dcc61327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94406e4e86a94017aee5d3c669c16f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b912ff98d6d54e0db0236788fbe3295c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "007d3b997b6942fea809f771a995d6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ffe29eb55ad4d3eb92a52e417dbd325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cae2e5a0d6e3489e866088d175620b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca1b0f36c3fa4d3c93694c921e39960f",
              "IPY_MODEL_16747245a023471c965aba9000e9e3ac",
              "IPY_MODEL_b0844bef58784d8e93aa2b23facf8ec3"
            ],
            "layout": "IPY_MODEL_8b7528e6dcff4b57a59d0b95bd7f7f37"
          }
        },
        "ca1b0f36c3fa4d3c93694c921e39960f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aeb39b9e92e40099bd7b399c0ed134a",
            "placeholder": "​",
            "style": "IPY_MODEL_756c5e367ca94e72a4ec5464b9474141",
            "value": "100%"
          }
        },
        "16747245a023471c965aba9000e9e3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c64280cdc864a0e9f42a85fa2f90b79",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_269ebcbaf7944489a052ac66ee9f8c5e",
            "value": 500
          }
        },
        "b0844bef58784d8e93aa2b23facf8ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edac7db063564ff99a919d253f97a3ea",
            "placeholder": "​",
            "style": "IPY_MODEL_7ad76e9675754eb19f4f605ca57534f8",
            "value": " 500/500 [00:53&lt;00:00,  9.40it/s]"
          }
        },
        "8b7528e6dcff4b57a59d0b95bd7f7f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aeb39b9e92e40099bd7b399c0ed134a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756c5e367ca94e72a4ec5464b9474141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c64280cdc864a0e9f42a85fa2f90b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "269ebcbaf7944489a052ac66ee9f8c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edac7db063564ff99a919d253f97a3ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad76e9675754eb19f4f605ca57534f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycx34gWpcZn7"
      },
      "source": [
        "## Set-up environment\n",
        "\n",
        "As usual, we first install HuggingFace Transformers, and Datasets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "LOfMEpdEA3YH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpak2KOoKqOg",
        "outputId": "6fdba0b3-c70b-4eae-8ebe-624670b39747"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 17 00:59:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   24C    P0    46W / 400W |   1218MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RHYQezIGvsWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4b8VGvqVebM",
        "outputId": "0a1358c0-44f1-4eb6-973a-f5d5867b0ab5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHYPlPYccrwU"
      },
      "source": [
        "!pip install -q datasets"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltlte3TacqGC"
      },
      "source": [
        "## Prepare data\n",
        "\n",
        "Here we take a small portion of the IMDB dataset, a binary text classification dataset (\"is a movie review positive or negative?\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "42a4dfdcaacb4ba1aceb2c879eba1f8f",
            "c38cc9f86a6f4ba6b204bf4896fcae0c",
            "b60fbfc7e9944de4a69a3cf6a019a2d8",
            "986574032eb845a695007934ca6ac365",
            "231c11f423054636a3e39ca3ae95b2d5",
            "5a83957630514f37acb89d09eaae165e",
            "88910ecfa21e4990b2e96fd7bdac6694",
            "bb9afe368bd247ecab75b75d57b4176c",
            "9749a6d62d804961bf0f16932697dad3",
            "c7aa732b5d12408b958fec72195910cf",
            "18f8f463c2b44e24b1abfb87bfae7963"
          ]
        },
        "id": "vGSKcPLEcd1J",
        "outputId": "933e9b70-90c9-4419-e653-c24ab5ab676a"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_ds, test_ds = load_dataset(\"imdb\", split=['train', 'test'])\n",
        "# train_ds, test_ds = load_dataset(\"imdb\", split=['train[:10]+train[-10:]', 'test[:5]+test[-5:]'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42a4dfdcaacb4ba1aceb2c879eba1f8f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create id2label and label2id mappings, which are handy at inference time."
      ],
      "metadata": {
        "id": "psAnJj0MVgTQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2Waba6gcs36",
        "outputId": "f7fa12e7-c233-4c3f-ae24-396c022d96ca"
      },
      "source": [
        "labels = train_ds.features['label'].names\n",
        "print(labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neg', 'pos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex0KxN6pcwHS",
        "outputId": "6bd3046a-b145-4211-def2-f1d93659a353"
      },
      "source": [
        "id2label = {idx:label for idx, label in enumerate(labels)}\n",
        "label2id = {label:idx for idx, label in enumerate(labels)}\n",
        "print(id2label)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'neg', 1: 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we prepare the data for the model using the tokenizer. "
      ],
      "metadata": {
        "id": "xS3yzpYhVj9m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQphEjiAcxP6",
        "outputId": "6c74e712-fc8e-4657-808a-0873e20c98b2"
      },
      "source": [
        "from transformers import PerceiverTokenizer\n",
        "\n",
        "tokenizer = PerceiverTokenizer.from_pretrained(\"deepmind/language-perceiver\")\n",
        "\n",
        "train_ds = train_ds.map(lambda examples: tokenizer(examples['text'], padding=\"max_length\", truncation=True),\n",
        "                        batched=True)\n",
        "test_ds = test_ds.map(lambda examples: tokenizer(examples['text'], padding=\"max_length\", truncation=True),\n",
        "                      batched=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-e39610288037a868.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-ef218fb3f5e098a3.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the format to PyTorch tensors, and create familiar PyTorch dataloaders."
      ],
      "metadata": {
        "id": "-nrT_MtEVnkk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ7Aa2KudFO1"
      },
      "source": [
        "train_ds.set_format(type=\"torch\", columns=['input_ids', 'label'])\n",
        "test_ds.set_format(type=\"torch\", columns=['input_ids', 'label'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pEiNbDMdJJ0"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_ds, batch_size=10, shuffle=True)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=50)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we verify some things (always important to check out your data!)."
      ],
      "metadata": {
        "id": "HivHZS1wVsCj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2heqUKfedOt-",
        "outputId": "c00828c4-4b6f-4758-9b2f-d21f1aac4198"
      },
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "for k,v in batch.items():\n",
        "  print(k,v.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label torch.Size([10])\n",
            "input_ids torch.Size([10, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "d_tt4gIUdP3s",
        "outputId": "92eb1a63-90d2-4d2f-b8d0-bc1c496d1821"
      },
      "source": [
        "tokenizer.decode(batch['input_ids'][3])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[CLS]Man, this movie sucked big time! I didn't even manage to see the hole thing (my girlfriend did though). Really bad acting, computer animations so bad you just laugh (woman to werewolf), strange clips, the list goes on and on. Don't know if its just me or does this movie remind you of a porn movie? And I don't mean all the naked ladys... It's something about the light or something... This could maybee become a classic just because of the bad acting and all the naked women, but not because it's an original movie white a nice plot twist. My final words are: Don't see it! It's not worth the time. If you wanna see it because the nakedness there's lots of better ones to see![SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDVhJ1nVg5d4",
        "outputId": "9bac7da6-b294-4aaa-8ee7-231fdc186791"
      },
      "source": [
        "batch['label']"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_ds['label'].double().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uZgPUe4Dr2x",
        "outputId": "b3cdb453-aa43-4455-9d8d-e085bbe389c2"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5000, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DixaPHgLdUMG"
      },
      "source": [
        "## Define model\n",
        "\n",
        "Next, we define our model, and put it on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjd2opzAdRQd",
        "outputId": "77816610-2832-4606-9b92-507a094cfbc1"
      },
      "source": [
        "# preprocessor we customized to use the tagkop encoder\n",
        "from tagkop_encoding_functions import (\n",
        "    PerceiverImagePreprocessor,\n",
        "    TagkopPerceiverTextPreprocessor,\n",
        ")\n",
        "from transformers import PerceiverForSequenceClassification\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers.models.perceiver.modeling_perceiver import (\n",
        "    PerceiverConfig,\n",
        "    PerceiverModel,\n",
        "    PerceiverClassificationDecoder,\n",
        "    PerceiverTextPreprocessor,\n",
        "    PerceiverClassificationDecoder\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "config = PerceiverConfig(\n",
        "    num_self_attends_per_block = 4,\n",
        "    d_model = 64\n",
        ")\n",
        "\n",
        "print('config', config)\n",
        "\n",
        "# Vanilla Perceiver Encodings\n",
        "\n",
        "\n",
        "preprocessor = PerceiverTextPreprocessor(config)\n",
        "\n",
        "# Our new awesome encodings\n",
        "# preprocessor = TagkopPerceiverTextPreprocessor(config)\n",
        "\n",
        "\n",
        "# preprocessor = PerceiverImagePreprocessor(config,\n",
        "#                                           in_channels=1,\n",
        "#                                           prep_type=\"1d\",\n",
        "#                                           position_encoding_type=\"fourier\",\n",
        "                                          \n",
        "\n",
        "#                                           concat_or_add_pos=\"add\",\n",
        "#                                           out_channels=64,\n",
        "#                                           project_pos_dim=64,\n",
        "#                                           # tagkop_position_encoding_kwargs=dict(\n",
        "#                                           #   num_channels=64,\n",
        "#                                           #   index_dims=config.image_size**2,\n",
        "#                                           #   ds=\"imdb\"\n",
        "#                                           #   ),\n",
        "#                                           fourier_position_encoding_kwargs = dict(\n",
        "#                                               concat_pos=False, max_resolution=(224, 224), num_bands=16, sine_only=False\n",
        "#                                           )\n",
        "#                                       )\n",
        "\n",
        "decoder = PerceiverClassificationDecoder(config,\n",
        "                                          num_channels=config.d_latents,\n",
        "                                          trainable_position_encoding_kwargs=dict(num_channels=config.d_latents, index_dims=1),\n",
        "                                          use_query_residual=True,\n",
        "                                         )\n",
        "\n",
        "# num_self_attends_per_block, num_self_attention_heads, num_cross_attention_heads to something more reasonable and out_channels project_pos_dim and num_channels to 64\n",
        "model = PerceiverModel(config, input_preprocessor=preprocessor, decoder=decoder)\n",
        "\n",
        "\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config PerceiverConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"audio_samples_per_frame\": 1920,\n",
            "  \"cross_attention_shape_for_attention\": \"kv\",\n",
            "  \"cross_attention_widening_factor\": 1,\n",
            "  \"d_latents\": 1280,\n",
            "  \"d_model\": 64,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"image_size\": 56,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"perceiver\",\n",
            "  \"num_blocks\": 1,\n",
            "  \"num_cross_attention_heads\": 8,\n",
            "  \"num_frames\": 16,\n",
            "  \"num_latents\": 256,\n",
            "  \"num_self_attends_per_block\": 4,\n",
            "  \"num_self_attention_heads\": 8,\n",
            "  \"output_shape\": [\n",
            "    1,\n",
            "    16,\n",
            "    224,\n",
            "    224\n",
            "  ],\n",
            "  \"qk_channels\": null,\n",
            "  \"samples_per_patch\": 16,\n",
            "  \"self_attention_widening_factor\": 1,\n",
            "  \"train_size\": [\n",
            "    368,\n",
            "    496\n",
            "  ],\n",
            "  \"transformers_version\": \"4.25.0.dev0\",\n",
            "  \"use_query_residual\": true,\n",
            "  \"v_channels\": null,\n",
            "  \"vocab_size\": 262\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PerceiverModel(\n",
              "  (input_preprocessor): PerceiverTextPreprocessor(\n",
              "    (embeddings): Embedding(262, 64)\n",
              "    (position_embeddings): Embedding(2048, 64)\n",
              "  )\n",
              "  (embeddings): PerceiverEmbeddings()\n",
              "  (encoder): PerceiverEncoder(\n",
              "    (cross_attention): PerceiverLayer(\n",
              "      (attention): PerceiverAttention(\n",
              "        (self): PerceiverSelfAttention(\n",
              "          (layernorm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "          (layernorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (query): Linear(in_features=1280, out_features=64, bias=True)\n",
              "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (output): PerceiverSelfOutput(\n",
              "          (dense): Linear(in_features=64, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): PerceiverMLP(\n",
              "        (dense1): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (intermediate_act_fn): GELUActivation()\n",
              "        (dense2): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (self_attends): ModuleList(\n",
              "      (0): PerceiverLayer(\n",
              "        (attention): PerceiverAttention(\n",
              "          (self): PerceiverSelfAttention(\n",
              "            (layernorm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            (layernorm2): Identity()\n",
              "            (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): PerceiverSelfOutput(\n",
              "            (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): PerceiverMLP(\n",
              "          (dense1): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "          (dense2): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (1): PerceiverLayer(\n",
              "        (attention): PerceiverAttention(\n",
              "          (self): PerceiverSelfAttention(\n",
              "            (layernorm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            (layernorm2): Identity()\n",
              "            (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): PerceiverSelfOutput(\n",
              "            (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): PerceiverMLP(\n",
              "          (dense1): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "          (dense2): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (2): PerceiverLayer(\n",
              "        (attention): PerceiverAttention(\n",
              "          (self): PerceiverSelfAttention(\n",
              "            (layernorm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            (layernorm2): Identity()\n",
              "            (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): PerceiverSelfOutput(\n",
              "            (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): PerceiverMLP(\n",
              "          (dense1): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "          (dense2): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (3): PerceiverLayer(\n",
              "        (attention): PerceiverAttention(\n",
              "          (self): PerceiverSelfAttention(\n",
              "            (layernorm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            (layernorm2): Identity()\n",
              "            (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): PerceiverSelfOutput(\n",
              "            (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): PerceiverMLP(\n",
              "          (dense1): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "          (dense2): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): PerceiverClassificationDecoder(\n",
              "    (decoder): PerceiverBasicDecoder(\n",
              "      (output_position_encodings): PerceiverTrainablePositionEncoding()\n",
              "      (positions_projection): Identity()\n",
              "      (decoding_cross_attention): PerceiverLayer(\n",
              "        (attention): PerceiverAttention(\n",
              "          (self): PerceiverSelfAttention(\n",
              "            (layernorm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            (layernorm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): PerceiverSelfOutput(\n",
              "            (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): PerceiverMLP(\n",
              "          (dense1): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "          (dense2): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (final_layer): Linear(in_features=1280, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can then do a forward pass as follows:\n",
        "tokenizer = PerceiverTokenizer()\n",
        "text = \"hello world\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "print(inputs)\n",
        "inputs.to(device)\n",
        "with torch.no_grad():\n",
        "   outputs = model(inputs=inputs.unsqueeze(1).to(device))\n",
        "logits = outputs.logits\n",
        "print('list(logits.shape): ', list(logits.shape))\n",
        "# to train, one can train the model using standard cross-entropy:\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "labels = torch.tensor([1]).to(device)\n",
        "loss = criterion(logits, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "XnkuVLD5VYN_",
        "outputId": "5b952ac1-214e-4ba1-ef61-7947c39efd5c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  4, 110, 107, 114, 114, 117,  38, 125, 117, 120, 114, 106,   5]])\n",
            "using imdb dataset\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3eb1569976d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m    \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'list(logits.shape): '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/perceiver/modeling_perceiver.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, attention_mask, subsampled_output_points, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_preprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodality_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_without_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m             \u001b[0mmodality_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tagkop_encoding_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, pos, network_input_is_1d)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported data format for conv1x1.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_without_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_network_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_input_is_1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mmodality_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Size for each modality, only needed for multimodal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tagkop_encoding_functions.py\u001b[0m in \u001b[0;36m_build_network_inputs\u001b[0;34m(self, inputs, network_input_is_1d)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0minputs_with_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_enc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_or_add_pos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0minputs_with_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_enc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs_with_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (13) must match the size of tensor b (2048) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P3jGwTMd29s"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Here we train the model using native PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aFtlQAxeddc-",
        "outputId": "dc8dade5-7bb7-47f5-a9cd-986b2feba577"
      },
      "source": [
        "from transformers import AdamW\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "model.train()\n",
        "\n",
        "\n",
        "batch = next(iter(train_dataloader))\n",
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/saved_model/small_network_model_fourier.pt')\n",
        "    print('saved model')\n",
        "    print(\"Epoch:\", epoch)\n",
        "    for i in range(10):\n",
        "    # for batch in tqdm(train_dataloader):\n",
        "         # get the inputs; \n",
        "         inputs = batch[\"input_ids\"].to(device)\n",
        "        #  attention_mask = batch[\"attention_mask\"].to(device)\n",
        "         labels = batch[\"label\"].to(device)\n",
        "\n",
        "         # zero the parameter gradients\n",
        "         optimizer.zero_grad()\n",
        "\n",
        "         # forward + backward + optimize\n",
        "         outputs = model(inputs=inputs)\n",
        "         logits = outputs.logits\n",
        "         \n",
        "         # to train, one can train the model using standard cross-entropy:\n",
        "         criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "         loss = criterion(logits, labels)\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "         \n",
        "         \n",
        "         \n",
        "\n",
        "         # evaluate\n",
        "         predictions = outputs.logits.argmax(-1).cpu().detach().numpy()\n",
        "         accuracy = accuracy_score(y_true=batch[\"label\"].numpy(), y_pred=predictions)\n",
        "         print(f\"Loss: {loss.item()}, Accuracy: {accuracy}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved model\n",
            "Epoch: 0\n",
            "Loss: 0.9116876721382141, Accuracy: 0.4\n",
            "Loss: 4.553509712219238, Accuracy: 0.6\n",
            "Loss: 0.7355924844741821, Accuracy: 0.7\n",
            "Loss: 3.4581539630889893, Accuracy: 0.4\n",
            "Loss: 1.4204754829406738, Accuracy: 0.4\n",
            "Loss: 1.0859565734863281, Accuracy: 0.6\n",
            "Loss: 1.576385736465454, Accuracy: 0.6\n",
            "Loss: 1.2882251739501953, Accuracy: 0.6\n",
            "Loss: 0.7216700315475464, Accuracy: 0.6\n",
            "Loss: 0.7490414381027222, Accuracy: 0.6\n",
            "saved model\n",
            "Epoch: 1\n",
            "Loss: 1.0918055772781372, Accuracy: 0.4\n",
            "Loss: 0.9054195284843445, Accuracy: 0.4\n",
            "Loss: 0.6239315867424011, Accuracy: 0.6\n",
            "Loss: 0.691170334815979, Accuracy: 0.6\n",
            "Loss: 0.8408317565917969, Accuracy: 0.6\n",
            "Loss: 0.8485921025276184, Accuracy: 0.6\n",
            "Loss: 0.7366556525230408, Accuracy: 0.6\n",
            "Loss: 0.6212990880012512, Accuracy: 0.7\n",
            "Loss: 0.6274121403694153, Accuracy: 0.6\n",
            "Loss: 0.736826479434967, Accuracy: 0.8\n",
            "saved model\n",
            "Epoch: 2\n",
            "Loss: 0.7458535432815552, Accuracy: 0.7\n",
            "Loss: 0.6682078838348389, Accuracy: 0.7\n",
            "Loss: 0.6056714057922363, Accuracy: 0.7\n",
            "Loss: 0.6214624643325806, Accuracy: 0.7\n",
            "Loss: 0.6643016338348389, Accuracy: 0.6\n",
            "Loss: 0.6765402555465698, Accuracy: 0.6\n",
            "Loss: 0.6537300944328308, Accuracy: 0.6\n",
            "Loss: 0.6044132113456726, Accuracy: 0.7\n",
            "Loss: 0.5981290936470032, Accuracy: 0.6\n",
            "Loss: 0.6247233152389526, Accuracy: 0.6\n",
            "saved model\n",
            "Epoch: 3\n",
            "Loss: 0.6402540802955627, Accuracy: 0.7\n",
            "Loss: 0.6311718821525574, Accuracy: 0.7\n",
            "Loss: 0.6092984080314636, Accuracy: 0.6\n",
            "Loss: 0.5987502336502075, Accuracy: 0.7\n",
            "Loss: 0.604925274848938, Accuracy: 0.7\n",
            "Loss: 0.6073575615882874, Accuracy: 0.7\n",
            "Loss: 0.6127153635025024, Accuracy: 0.7\n",
            "Loss: 0.593233585357666, Accuracy: 0.7\n",
            "Loss: 0.5888651609420776, Accuracy: 0.7\n",
            "Loss: 0.5831118822097778, Accuracy: 0.6\n",
            "saved model\n",
            "Epoch: 4\n",
            "Loss: 0.5878325700759888, Accuracy: 0.6\n",
            "Loss: 0.5937627553939819, Accuracy: 0.6\n",
            "Loss: 0.5859473943710327, Accuracy: 0.6\n",
            "Loss: 0.5747441053390503, Accuracy: 0.6\n",
            "Loss: 0.5754879713058472, Accuracy: 0.6\n",
            "Loss: 0.5850244164466858, Accuracy: 0.7\n",
            "Loss: 0.5729710459709167, Accuracy: 0.7\n",
            "Loss: 0.5664327144622803, Accuracy: 0.6\n",
            "Loss: 0.5643692016601562, Accuracy: 0.6\n",
            "Loss: 0.5544694662094116, Accuracy: 0.6\n",
            "saved model\n",
            "Epoch: 5\n",
            "Loss: 0.5592849850654602, Accuracy: 0.7\n",
            "Loss: 0.5448601841926575, Accuracy: 0.7\n",
            "Loss: 0.5388075113296509, Accuracy: 0.7\n",
            "Loss: 0.5275112986564636, Accuracy: 0.7\n",
            "Loss: 0.521371066570282, Accuracy: 0.7\n",
            "Loss: 0.5136476755142212, Accuracy: 0.7\n",
            "Loss: 0.5043951272964478, Accuracy: 0.7\n",
            "Loss: 0.4980406165122986, Accuracy: 0.7\n",
            "Loss: 0.48829975724220276, Accuracy: 0.7\n",
            "Loss: 0.4635482728481293, Accuracy: 0.7\n",
            "saved model\n",
            "Epoch: 6\n",
            "Loss: 0.4491785168647766, Accuracy: 0.8\n",
            "Loss: 0.4373982846736908, Accuracy: 0.8\n",
            "Loss: 0.4159439504146576, Accuracy: 0.8\n",
            "Loss: 0.4087931215763092, Accuracy: 0.8\n",
            "Loss: 0.37751561403274536, Accuracy: 0.8\n",
            "Loss: 0.3674125373363495, Accuracy: 0.8\n",
            "Loss: 0.34011581540107727, Accuracy: 0.8\n",
            "Loss: 0.34177300333976746, Accuracy: 0.8\n",
            "Loss: 0.35846975445747375, Accuracy: 0.8\n",
            "Loss: 0.347247838973999, Accuracy: 0.8\n",
            "saved model\n",
            "Epoch: 7\n",
            "Loss: 0.32659393548965454, Accuracy: 0.8\n",
            "Loss: 0.33252882957458496, Accuracy: 0.8\n",
            "Loss: 0.3413735032081604, Accuracy: 0.8\n",
            "Loss: 0.34123003482818604, Accuracy: 0.7\n",
            "Loss: 0.306296169757843, Accuracy: 0.9\n",
            "Loss: 0.33031603693962097, Accuracy: 0.8\n",
            "Loss: 0.3327884078025818, Accuracy: 0.8\n",
            "Loss: 0.33539915084838867, Accuracy: 0.7\n",
            "Loss: 0.34420710802078247, Accuracy: 0.7\n",
            "Loss: 0.32498666644096375, Accuracy: 0.8\n",
            "saved model\n",
            "Epoch: 8\n",
            "Loss: 0.31542593240737915, Accuracy: 0.8\n",
            "Loss: 0.32633841037750244, Accuracy: 0.8\n",
            "Loss: 0.3259156048297882, Accuracy: 0.7\n",
            "Loss: 0.3209476172924042, Accuracy: 0.8\n",
            "Loss: 0.313310831785202, Accuracy: 0.8\n",
            "Loss: 0.3165505528450012, Accuracy: 0.8\n",
            "Loss: 0.33813804388046265, Accuracy: 0.7\n",
            "Loss: 0.3193965554237366, Accuracy: 0.7\n",
            "Loss: 0.30384716391563416, Accuracy: 0.8\n",
            "Loss: 0.3346033990383148, Accuracy: 0.8\n",
            "saved model\n",
            "Epoch: 9\n",
            "Loss: 0.3236205577850342, Accuracy: 0.7\n",
            "Loss: 0.3122733235359192, Accuracy: 0.8\n",
            "Loss: 0.30949825048446655, Accuracy: 0.8\n",
            "Loss: 0.30149513483047485, Accuracy: 0.8\n",
            "Loss: 0.3272061347961426, Accuracy: 0.6\n",
            "Loss: 0.30287665128707886, Accuracy: 0.8\n",
            "Loss: 0.32825952768325806, Accuracy: 0.8\n",
            "Loss: 0.3088507056236267, Accuracy: 0.8\n",
            "Loss: 0.3036399483680725, Accuracy: 0.8\n",
            "Loss: 0.292683482170105, Accuracy: 0.8\n",
            "saved model\n",
            "Epoch: 10\n",
            "Loss: 0.3167802691459656, Accuracy: 0.8\n",
            "Loss: 0.32804426550865173, Accuracy: 0.7\n",
            "Loss: 0.28982558846473694, Accuracy: 0.8\n",
            "Loss: 0.3116169571876526, Accuracy: 0.7\n",
            "Loss: 0.2997993528842926, Accuracy: 0.8\n",
            "Loss: 0.27227309346199036, Accuracy: 0.9\n",
            "Loss: 0.27917414903640747, Accuracy: 0.9\n",
            "Loss: 0.2747514843940735, Accuracy: 0.8\n",
            "Loss: 0.294406920671463, Accuracy: 0.8\n",
            "Loss: 0.27962952852249146, Accuracy: 0.8\n",
            "saved model\n",
            "Epoch: 11\n",
            "Loss: 0.26022863388061523, Accuracy: 0.9\n",
            "Loss: 0.27156075835227966, Accuracy: 0.8\n",
            "Loss: 0.2728862166404724, Accuracy: 0.8\n",
            "Loss: 0.24127277731895447, Accuracy: 0.8\n",
            "Loss: 0.2216053456068039, Accuracy: 0.9\n",
            "Loss: 0.23280951380729675, Accuracy: 0.9\n",
            "Loss: 0.23844996094703674, Accuracy: 0.8\n",
            "Loss: 0.20222978293895721, Accuracy: 0.9\n",
            "Loss: 0.21940629184246063, Accuracy: 0.9\n",
            "Loss: 0.22585761547088623, Accuracy: 0.9\n",
            "saved model\n",
            "Epoch: 12\n",
            "Loss: 0.24397501349449158, Accuracy: 0.8\n",
            "Loss: 0.20982499420642853, Accuracy: 0.9\n",
            "Loss: 0.20256808400154114, Accuracy: 0.9\n",
            "Loss: 0.22208920121192932, Accuracy: 0.9\n",
            "Loss: 0.21905489265918732, Accuracy: 0.9\n",
            "Loss: 0.21431422233581543, Accuracy: 0.9\n",
            "Loss: 0.25831690430641174, Accuracy: 0.8\n",
            "Loss: 0.1964251548051834, Accuracy: 0.9\n",
            "Loss: 0.23514267802238464, Accuracy: 0.9\n",
            "Loss: 0.18434065580368042, Accuracy: 0.9\n",
            "saved model\n",
            "Epoch: 13\n",
            "Loss: 0.19497598707675934, Accuracy: 0.9\n",
            "Loss: 0.2090892344713211, Accuracy: 0.9\n",
            "Loss: 0.22120611369609833, Accuracy: 0.9\n",
            "Loss: 0.19363483786582947, Accuracy: 0.9\n",
            "Loss: 0.1921319216489792, Accuracy: 0.9\n",
            "Loss: 0.1869589388370514, Accuracy: 0.9\n",
            "Loss: 0.182424858212471, Accuracy: 0.9\n",
            "Loss: 0.1896304339170456, Accuracy: 0.9\n",
            "Loss: 0.16974270343780518, Accuracy: 0.9\n",
            "Loss: 0.16899634897708893, Accuracy: 0.9\n",
            "saved model\n",
            "Epoch: 14\n",
            "Loss: 0.1660400927066803, Accuracy: 0.9\n",
            "Loss: 0.17225097119808197, Accuracy: 0.9\n",
            "Loss: 0.18338078260421753, Accuracy: 0.9\n",
            "Loss: 0.15395961701869965, Accuracy: 0.9\n",
            "Loss: 0.1451401710510254, Accuracy: 0.9\n",
            "Loss: 0.12435565143823624, Accuracy: 1.0\n",
            "Loss: 0.11424939334392548, Accuracy: 0.9\n",
            "Loss: 0.10808241367340088, Accuracy: 1.0\n",
            "Loss: 0.10118992626667023, Accuracy: 0.9\n",
            "Loss: 0.0896373838186264, Accuracy: 1.0\n",
            "saved model\n",
            "Epoch: 15\n",
            "Loss: 0.06801070272922516, Accuracy: 1.0\n",
            "Loss: 0.05863949656486511, Accuracy: 1.0\n",
            "Loss: 0.04597122222185135, Accuracy: 1.0\n",
            "Loss: 0.020264882594347, Accuracy: 1.0\n",
            "Loss: 0.022769607603549957, Accuracy: 1.0\n",
            "Loss: 0.011483238078653812, Accuracy: 1.0\n",
            "Loss: 0.011728165671229362, Accuracy: 1.0\n",
            "Loss: 0.0013624653220176697, Accuracy: 1.0\n",
            "Loss: 0.001751311356201768, Accuracy: 1.0\n",
            "Loss: 0.002532229060307145, Accuracy: 1.0\n",
            "saved model\n",
            "Epoch: 16\n",
            "Loss: 0.0022764611057937145, Accuracy: 1.0\n",
            "Loss: 0.0010375366546213627, Accuracy: 1.0\n",
            "Loss: 0.0008567519253119826, Accuracy: 1.0\n",
            "Loss: 0.0022351830266416073, Accuracy: 1.0\n",
            "Loss: 0.004424475599080324, Accuracy: 1.0\n",
            "Loss: 0.0002919937251135707, Accuracy: 1.0\n",
            "Loss: 0.3290005028247833, Accuracy: 0.9\n",
            "Loss: 2.462484836578369, Accuracy: 0.7\n",
            "Loss: 0.31947875022888184, Accuracy: 0.8\n",
            "Loss: 0.30085688829421997, Accuracy: 0.8\n",
            "saved model\n",
            "Epoch: 17\n",
            "Loss: 0.11063678562641144, Accuracy: 1.0\n",
            "Loss: 0.1867748647928238, Accuracy: 0.8\n",
            "Loss: 0.08815590292215347, Accuracy: 1.0\n",
            "Loss: 0.20452208817005157, Accuracy: 0.9\n",
            "Loss: 0.11531680822372437, Accuracy: 0.9\n",
            "Loss: 0.1282498836517334, Accuracy: 0.9\n",
            "Loss: 0.046138714998960495, Accuracy: 1.0\n",
            "Loss: 0.11039401590824127, Accuracy: 0.9\n",
            "Loss: 0.03163156658411026, Accuracy: 1.0\n",
            "Loss: 0.05326824635267258, Accuracy: 1.0\n",
            "saved model\n",
            "Epoch: 18\n",
            "Loss: 0.028618931770324707, Accuracy: 1.0\n",
            "Loss: 0.017131993547081947, Accuracy: 1.0\n",
            "Loss: 0.032530978322029114, Accuracy: 1.0\n",
            "Loss: 0.007527891546487808, Accuracy: 1.0\n",
            "Loss: 0.001523178187198937, Accuracy: 1.0\n",
            "Loss: 0.004804516676813364, Accuracy: 1.0\n",
            "Loss: 0.008542188443243504, Accuracy: 1.0\n",
            "Loss: 0.00026036211056634784, Accuracy: 1.0\n",
            "Loss: 0.00014378181367646903, Accuracy: 1.0\n",
            "Loss: 0.0002003342378884554, Accuracy: 1.0\n",
            "saved model\n",
            "Epoch: 19\n",
            "Loss: 0.0004998294170945883, Accuracy: 1.0\n",
            "Loss: 0.0007484821835532784, Accuracy: 1.0\n",
            "Loss: 0.0017386290710419416, Accuracy: 1.0\n",
            "Loss: 0.0021193348802626133, Accuracy: 1.0\n",
            "Loss: 0.0007557862554676831, Accuracy: 1.0\n",
            "Loss: 0.00017434728215448558, Accuracy: 1.0\n",
            "Loss: 5.9329373470973223e-05, Accuracy: 1.0\n",
            "Loss: 2.6617059120326303e-05, Accuracy: 1.0\n",
            "Loss: 1.422104105586186e-05, Accuracy: 1.0\n",
            "Loss: 8.21332105260808e-06, Accuracy: 1.0\n",
            "saved model\n",
            "Epoch: 20\n",
            "Loss: 4.37492371929693e-06, Accuracy: 1.0\n",
            "Loss: 3.6120013646723237e-06, Accuracy: 1.0\n",
            "Loss: 2.777552708721487e-06, Accuracy: 1.0\n",
            "Loss: 1.919259830174269e-06, Accuracy: 1.0\n",
            "Loss: 1.6927639308050857e-06, Accuracy: 1.0\n",
            "Loss: 1.1444059282439412e-06, Accuracy: 1.0\n",
            "Loss: 9.298304348703823e-07, Accuracy: 1.0\n",
            "Loss: 8.702259037818294e-07, Accuracy: 1.0\n",
            "Loss: 7.987008530108142e-07, Accuracy: 1.0\n",
            "Loss: 7.510171826652368e-07, Accuracy: 1.0\n",
            "saved model\n",
            "Epoch: 21\n",
            "Loss: 6.437292654482007e-07, Accuracy: 1.0\n",
            "Loss: 5.722038736166724e-07, Accuracy: 1.0\n",
            "Loss: 5.60282956030278e-07, Accuracy: 1.0\n",
            "Loss: 5.00678481785144e-07, Accuracy: 1.0\n",
            "Loss: 4.172321439455118e-07, Accuracy: 1.0\n",
            "Loss: 4.52994839861276e-07, Accuracy: 1.0\n",
            "Loss: 3.8146941960803815e-07, Accuracy: 1.0\n",
            "Loss: 3.814694480297476e-07, Accuracy: 1.0\n",
            "Loss: 3.337858061058796e-07, Accuracy: 1.0\n",
            "Loss: 3.4570672369227395e-07, Accuracy: 1.0\n",
            "saved model\n",
            "Epoch: 22\n",
            "Loss: 3.4570672369227395e-07, Accuracy: 1.0\n",
            "Loss: 3.814694480297476e-07, Accuracy: 1.0\n",
            "Loss: 3.576276412786683e-07, Accuracy: 1.0\n",
            "Loss: 3.099439709330909e-07, Accuracy: 1.0\n",
            "Loss: 3.337858061058796e-07, Accuracy: 1.0\n",
            "Loss: 3.099439709330909e-07, Accuracy: 1.0\n",
            "Loss: 2.7418121817390784e-07, Accuracy: 1.0\n",
            "Loss: 3.2186488851948525e-07, Accuracy: 1.0\n",
            "Loss: 2.861021641820116e-07, Accuracy: 1.0\n",
            "Loss: 3.2186488851948525e-07, Accuracy: 1.0\n",
            "saved model\n",
            "Epoch: 23\n",
            "Loss: 3.2186488851948525e-07, Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-557faf64b3ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m          \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m          \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m          \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/perceiver/modeling_perceiver.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, attention_mask, subsampled_output_points, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m         )\n\u001b[1;32m    904\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/perceiver/modeling_perceiver.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, inputs, inputs_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m                 )\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/perceiver/modeling_perceiver.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, inputs, inputs_mask, output_attentions)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0minputs_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         )\n\u001b[1;32m    474\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/perceiver/modeling_perceiver.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, inputs, inputs_mask, output_attentions)\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0minputs_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         )\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/perceiver/modeling_perceiver.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, inputs, inputs_mask, output_attentions)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Take the dot product between the queries and keys to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_head_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcsR-ct94W1h"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "Finally, we evaluate the model on the test set. We use the Datasets library to compute the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/saved_model/small_network_model_fourier_embeddings.pt')"
      ],
      "metadata": {
        "id": "PO50YaWkuq5N"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6VTC2Eqfn3x",
        "outputId": "e1b65d36-fce9-43e3-934c-38b128d7c3fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import torch\n",
        "# checkpoint = torch.load('/content/drive/MyDrive/saved_model/small_network_model.pt')\n",
        "# model.load_state_dict(checkpoint)\n",
        "# model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "QgTRYkGEOJkU",
        "outputId": "c4e8aba9-a9e1-4f93-d4f0-26a22e866b4a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2727f092fb0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/saved_model/small_network_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1605\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PerceiverModel:\n\tUnexpected key(s) in state_dict: \"encoder.self_attends.4.attention.self.layernorm1.weight\", \"encoder.self_attends.4.attention.self.layernorm1.bias\", \"encoder.self_attends.4.attention.self.query.weight\", \"encoder.self_attends.4.attention.self.query.bias\", \"encoder.self_attends.4.attention.self.key.weight\", \"encoder.self_attends.4.attention.self.key.bias\", \"encoder.self_attends.4.attention.self.value.weight\", \"encoder.self_attends.4.attention.self.value.bias\", \"encoder.self_attends.4.attention.output.dense.weight\", \"encoder.self_attends.4.attention.output.dense.bias\", \"encoder.self_attends.4.layernorm.weight\", \"encoder.self_attends.4.layernorm.bias\", \"encoder.self_attends.4.mlp.dense1.weight\", \"encoder.self_attends.4.mlp.dense1.bias\", \"encoder.self_attends.4.mlp.dense2.weight\", \"encoder.self_attends.4.mlp.dense2.bias\", \"encoder.self_attends.5.attention.self.layernorm1.weight\", \"encoder.self_attends.5.attention.self.layernorm1.bias\", \"encoder.self_attends.5.attention.self.query.weight\", \"encoder.self_attends.5.attention.self.query.bias\", \"encoder.self_attends.5.attention.self.key.weight\", \"encoder.self_attends.5.attention.self.key.bias\", \"encoder.self_attends.5.attention.self.value.weight\", \"encoder.self_attends.5.attention.self.value.bias\", \"encoder.self_attends.5.attention.output.dense.weight\", \"encoder.self_attends.5.attention.output.dense.bias\", \"encoder.self_attends.5.layernorm.weight\", \"encoder.self_attends.5.layernorm.bias\", \"encoder.self_attends.5.mlp.dense1.weight\",..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkQjXLMx2ZJn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "dd2549fe803f4fe98f009a882b8110fe",
            "52d0de07ee414a8087bd85ae0239776d",
            "b95832bbbb374016baf0f3f7459314f7",
            "f079e026c2bc40659ec8a5cbb45f801c",
            "a078920956c149249ba9579d54d376d7",
            "f36037a6c2ac464195f753310a80278a",
            "a069f41bc54c4861ac3b25b88b828a6b",
            "2c9b3cb072414e7e9d62805ec9a2d90d",
            "02f398e8aa884dcfb8ea0f88e516f7ce",
            "f6d2655749074a7ea959a8542e56e147",
            "4a722eadc7954ca6adf678dbb217a31a",
            "7a9a2c37235f445fb50417e08b539973",
            "2b257c583501471186c0e8d43ce22fd5",
            "a23322e5b92e47dabca5b6136ed2d59e",
            "4c8a6478d4d2416eac1c25339231daa5",
            "d514345ccf0242f1b2a48d415f922b1c",
            "df2e565a49c4441d821a7006e23efc39",
            "8bcdf54658564c1190311ef0dcc61327",
            "94406e4e86a94017aee5d3c669c16f40",
            "b912ff98d6d54e0db0236788fbe3295c",
            "007d3b997b6942fea809f771a995d6cc",
            "9ffe29eb55ad4d3eb92a52e417dbd325"
          ]
        },
        "outputId": "614c7ea3-a8c7-4954-c804-4fc8bbca141a"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from datasets import load_metric\n",
        "\n",
        "accuracy = load_metric(\"accuracy\")\n",
        "\n",
        "model.eval()\n",
        "for batch in tqdm(test_dataloader):\n",
        "      # get the inputs; \n",
        "      inputs = batch[\"input_ids\"].to(device)\n",
        "      attention_mask = batch[\"attention_mask\"].to(device)\n",
        "      labels = batch[\"label\"].to(device)\n",
        "\n",
        "      # forward pass\n",
        "      outputs = model(inputs=inputs, attention_mask=attention_mask)\n",
        "      logits = outputs.logits \n",
        "      predictions = logits.argmax(-1).cpu().detach().numpy()\n",
        "      references = batch[\"label\"].numpy()\n",
        "      accuracy.add_batch(predictions=predictions, references=references)\n",
        "\n",
        "final_score = accuracy.compute()\n",
        "print(\"Accuracy on test set:\", final_score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd2549fe803f4fe98f009a882b8110fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a9a2c37235f445fb50417e08b539973"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: {'accuracy': 0.62816}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TAGOP\n",
        "from tqdm.notebook import tqdm\n",
        "from datasets import load_metric\n",
        "\n",
        "accuracy = load_metric(\"accuracy\")\n",
        "\n",
        "model.eval()\n",
        "for batch in tqdm(test_dataloader):\n",
        "      # get the inputs; \n",
        "      inputs = batch[\"input_ids\"].to(device)\n",
        "      labels = batch[\"label\"].to(device)\n",
        "\n",
        "      # forward pass\n",
        "      outputs = model(inputs=inputs.unsqueeze(1))\n",
        "      logits = outputs.logits \n",
        "      predictions = logits.argmax(-1).cpu().detach().numpy()\n",
        "      references = batch[\"label\"].numpy()\n",
        "      accuracy.add_batch(predictions=predictions, references=references)\n",
        "\n",
        "final_score = accuracy.compute()\n",
        "print(\"Accuracy on test set:\", final_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cae2e5a0d6e3489e866088d175620b97",
            "ca1b0f36c3fa4d3c93694c921e39960f",
            "16747245a023471c965aba9000e9e3ac",
            "b0844bef58784d8e93aa2b23facf8ec3",
            "8b7528e6dcff4b57a59d0b95bd7f7f37",
            "6aeb39b9e92e40099bd7b399c0ed134a",
            "756c5e367ca94e72a4ec5464b9474141",
            "0c64280cdc864a0e9f42a85fa2f90b79",
            "269ebcbaf7944489a052ac66ee9f8c5e",
            "edac7db063564ff99a919d253f97a3ea",
            "7ad76e9675754eb19f4f605ca57534f8"
          ]
        },
        "id": "LQ0bO_bf60rZ",
        "outputId": "fdc147fa-51b8-4340-92af-f0c3a71d2429"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cae2e5a0d6e3489e866088d175620b97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "using imdb dataset\n",
            "Accuracy on test set: {'accuracy': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liX2IdFPfYix"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbVxJYSNfGvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d872fb02-6e5d-4855-8d3f-02016c61cf5a"
      },
      "source": [
        "text = \"I hated this movie, it's really bad.\"\n",
        "\n",
        "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# forward pass\n",
        "outputs = model(inputs=input_ids.to(device))\n",
        "logits = outputs.logits \n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "\n",
        "print(\"Predicted:\", model.config.id2label[predicted_class_idx])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: LABEL_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33ll9igqfrqk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}